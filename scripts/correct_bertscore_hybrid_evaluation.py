#!/usr/bin/env python3
"""
ì˜¬ë°”ë¥¸ BERTScore ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì˜ë£Œ ì±—ë´‡ í‰ê°€
- ì˜¤ì§ test ë°ì´í„°ë§Œ ì‚¬ìš© (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
- ê³µì •í•œ ì„±ëŠ¥ í‰ê°€
"""

import os
import json
import time
import random
from datetime import datetime
from typing import Dict, List, Tuple, Any
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from bert_score import score
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["TOKENIZERS_PARALLELISM"] = "false"

class CorrectBERTScoreHybridEvaluator:
    def __init__(self, model_path: str = "models/medical_finetuned_improved"):
        """ì˜¬ë°”ë¥¸ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ BERTScore í‰ê°€ì ì´ˆê¸°í™”"""
        self.model_path = model_path
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        # BERT ëª¨ë¸ ì„¤ì •
        self.bert_model = "bert-base-multilingual-cased"
        print(f"ğŸ§  BERT ëª¨ë¸: {self.bert_model}")
        print(f"ğŸ“Š IDF ê°€ì¤‘ì¹˜: True")
        
        # ëª¨ë¸ ë¡œë”©
        self._load_model()
        
        # ì˜ë£Œ ì§€ì‹ë² ì´ìŠ¤
        self._load_medical_knowledge()
        
    def _load_model(self):
        """ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë”©"""
        print(f"\nğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_path,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                device_map="auto" if self.device == "cuda" else None
            )
            
            if self.device == "cpu":
                self.model = self.model.to(self.device)
                
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    def _load_medical_knowledge(self):
        """ì˜ë£Œ ì§€ì‹ë² ì´ìŠ¤ ë¡œë”©"""
        # ì‘ê¸‰ìƒí™© í‚¤ì›Œë“œ
        self.emergency_keywords = [
            "ì‹¬í•œ", "ê°‘ì‘ìŠ¤ëŸ¬ìš´", "ê¸‰ì„±", "ì‹¬ì¥", "í˜¸í¡ê³¤ë€", "ì˜ì‹ë¶ˆëª…", 
            "ëŒ€ëŸ‰ì¶œí˜ˆ", "ê³¨ì ˆ", "í™”ìƒ", "ì¤‘ë…", "ë‡Œì¡¸ì¤‘", "ì‹¬ê·¼ê²½ìƒ‰",
            "ì‘ê¸‰ì‹¤", "119", "êµ¬ê¸‰ì°¨", "ìƒëª…ìœ„í—˜", "ì¦‰ì‹œ", "ê¸´ê¸‰"
        ]
        
        # ì¦ìƒ-ì§ˆë³‘ ë§¤í•‘
        self.symptom_disease_map = {
            "ê°ê¸°": ["ì½§ë¬¼", "ê¸°ì¹¨", "ëª©ì•„í””", "ë°œì—´", "ëª¸ì‚´"],
            "ë‹¹ë‡¨ë³‘": ["ë‹¤ë‡¨", "ë‹¤ìŒ", "ë‹¤ì‹", "ì²´ì¤‘ê°ì†Œ", "í”¼ë¡œ"],
            "ê³ í˜ˆì••": ["ë‘í†µ", "ì–´ì§€ëŸ¬ì›€", "ê°€ìŠ´ë‹µë‹µ", "í˜¸í¡ê³¤ë€"],
            "ìœ„ì—¼": ["ë³µí†µ", "ì†ì“°ë¦¼", "ë©”ìŠ¤êº¼ì›€", "êµ¬í† ", "ì†Œí™”ë¶ˆëŸ‰"],
            "ìš°ìš¸ì¦": ["ìš°ìš¸ê°", "ë¬´ê¸°ë ¥", "ìˆ˜ë©´ì¥ì• ", "ì‹ìš•ë¶€ì§„", "ì§‘ì¤‘ë ¥ì €í•˜"]
        }
        
        # ì§ˆë³‘-ì¹˜ë£Œ ë§¤í•‘
        self.disease_treatment_map = {
            "ê°ê¸°": {
                "ì•½ë¬¼": ["ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ", "ì´ë¶€í”„ë¡œíœ", "ì§„í•´ì œ", "ê±°ë‹´ì œ"],
                "ìì¡°": ["ì¶©ë¶„í•œ íœ´ì‹", "ìˆ˜ë¶„ ì„­ì·¨", "ë¹„íƒ€ë¯¼C", "ì˜¨ìˆ˜ ê°€ê¸€"],
                "ì˜ì‚¬ë°©ë¬¸": ["ê³ ì—´(38.5Â°C ì´ìƒ)", "3-4ì¼ ì´ìƒ ì§€ì†", "í˜¸í¡ê³¤ë€"]
            },
            "ë‹¹ë‡¨ë³‘": {
                "ì•½ë¬¼": ["ì˜ì‚¬ ì²˜ë°© ì•½ë¬¼"],
                "ìì¡°": ["ê·œì¹™ì ì¸ ì‹ì‚¬", "ìš´ë™", "í˜ˆë‹¹ ì¸¡ì •", "ì²´ì¤‘ ê´€ë¦¬"],
                "ì˜ì‚¬ë°©ë¬¸": ["í˜ˆë‹¹ ì¡°ì ˆ ë¶ˆëŸ‰", "í•©ë³‘ì¦ ì¦ìƒ", "ìƒˆë¡œìš´ ì¦ìƒ"]
            }
        }
    
    def _detect_emergency(self, text: str) -> bool:
        """ì‘ê¸‰ìƒí™© ê°ì§€"""
        text_lower = text.lower()
        for keyword in self.emergency_keywords:
            if keyword in text_lower:
                return True
        return False
    
    def _extract_symptoms(self, text: str) -> List[str]:
        """ì¦ìƒ ì¶”ì¶œ"""
        symptoms = []
        for disease, symptom_list in self.symptom_disease_map.items():
            for symptom in symptom_list:
                if symptom in text:
                    symptoms.append(disease)
                    break
        return symptoms
    
    def _get_rule_based_response(self, question: str) -> str:
        """ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        # ì‘ê¸‰ìƒí™© ê°ì§€
        if self._detect_emergency(question):
            return "ì‘ê¸‰ìƒí™©ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì¦‰ì‹œ 119ì— ì‹ ê³ í•˜ê±°ë‚˜ ì‘ê¸‰ì‹¤ì„ ë°©ë¬¸í•˜ì„¸ìš”."
        
        # ì¦ìƒ ê¸°ë°˜ ì‘ë‹µ
        symptoms = self._extract_symptoms(question)
        if symptoms:
            disease = symptoms[0]
            if disease in self.disease_treatment_map:
                treatment = self.disease_treatment_map[disease]
                response = f"{disease} ì¦ìƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. "
                
                if "ìì¡°" in treatment:
                    response += f"{', '.join(treatment['ìì¡°'])}ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. "
                
                if "ì•½ë¬¼" in treatment:
                    response += f"ë³µìš© ê°€ëŠ¥í•œ ì•½ë¬¼: {', '.join(treatment['ì•½ë¬¼'])}. "
                
                if "ì˜ì‚¬ë°©ë¬¸" in treatment:
                    response += f"ì˜ì‚¬ ë°©ë¬¸ì´ í•„ìš”í•œ ê²½ìš°: {', '.join(treatment['ì˜ì‚¬ë°©ë¬¸'])}."
                
                return response
        
        # ì¼ë°˜ì ì¸ ì‘ë‹µ
        return "ì¦ìƒì´ ì§€ì†ë˜ê±°ë‚˜ ì•…í™”ë˜ë©´ ì˜ë£Œì§„ê³¼ ìƒë‹´í•˜ì„¸ìš”."
    
    def _get_model_response(self, question: str) -> str:
        """ëª¨ë¸ ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"ì˜ë£Œ ìƒë‹´: {question}\nì˜ë£Œì§„:"
            
            # í† í¬ë‚˜ì´ì§•
            inputs = self.tokenizer.encode(prompt, return_tensors="pt").to(self.device)
            
            # ìƒì„±
            with torch.no_grad():
                outputs = self.model.generate(
                    inputs,
                    max_length=inputs.shape[1] + 100,
                    num_return_sequences=1,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    attention_mask=torch.ones_like(inputs)
                )
            
            # ë””ì½”ë”©
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            response = response.replace(prompt, "").strip()
            
            # ì‘ë‹µ ì •ë¦¬
            if "ì˜ë£Œì§„:" in response:
                response = response.split("ì˜ë£Œì§„:")[-1].strip()
            
            # ë°˜ë³µ ì œê±°
            lines = response.split('\n')
            cleaned_lines = []
            for line in lines:
                if line.strip() and not any(word in line for word in ["ì˜ë£Œì§„:", "ê°„í˜¸ì‚¬:", "ì§„ë£Œ:"]):
                    cleaned_lines.append(line.strip())
            
            if cleaned_lines:
                return cleaned_lines[0]
            else:
                return "ì •í™•í•œ ìƒë‹´ì„ ìœ„í•´ ì˜ë£Œì§„ê³¼ ì§ì ‘ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
                
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return "ì •í™•í•œ ìƒë‹´ì„ ìœ„í•´ ì˜ë£Œì§„ê³¼ ì§ì ‘ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
    
    def _is_valid_medical_response(self, response: str) -> bool:
        """ì˜ë£Œ ì‘ë‹µ ìœ íš¨ì„± ê²€ì‚¬"""
        invalid_patterns = [
            "ë‚´ì›í•œ í™˜ìì—ê²Œ",
            "ê°€ì¥ ì ì ˆí•œ ì¹˜ë£Œë²•ì€",
            "1 ìŠ¤í…Œë¡œì´ë“œ",
            "2 ëª¨ê¸°ì•½",
            "3 í”¼ë¶€íŠ¸ë ˆì´ë‹",
            "4 í”¼ë¶€íŠ¸ë ˆì´ë‹"
        ]
        
        for pattern in invalid_patterns:
            if pattern in response:
                return False
        return True
    
    def get_hybrid_response(self, question: str) -> Tuple[str, str, bool, List[str], float]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì‘ë‹µ ìƒì„±"""
        start_time = time.time()
        
        # 1. ì‘ê¸‰ìƒí™© ìš°ì„  ì²´í¬
        is_emergency = self._detect_emergency(question)
        if is_emergency:
            response = "ì‘ê¸‰ìƒí™©ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì¦‰ì‹œ 119ì— ì‹ ê³ í•˜ê±°ë‚˜ ì‘ê¸‰ì‹¤ì„ ë°©ë¬¸í•˜ì„¸ìš”."
            response_time = time.time() - start_time
            return response, "emergency", is_emergency, [], response_time
        
        # 2. ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ ì‹œë„
        rule_response = self._get_rule_based_response(question)
        if rule_response and len(rule_response) > 20:  # ì¶©ë¶„í•œ ê¸¸ì´ì˜ ì‘ë‹µ
            response_time = time.time() - start_time
            symptoms = self._extract_symptoms(question)
            return rule_response, "rule_based", is_emergency, symptoms, response_time
        
        # 3. ëª¨ë¸ ê¸°ë°˜ ì‘ë‹µ ì‹œë„
        model_response = self._get_model_response(question)
        if self._is_valid_medical_response(model_response):
            response_time = time.time() - start_time
            symptoms = self._extract_symptoms(question)
            return model_response, "model_based", is_emergency, symptoms, response_time
        
        # 4. í´ë°± ì‘ë‹µ
        fallback_response = "ì •í™•í•œ ìƒë‹´ì„ ìœ„í•´ ì˜ë£Œì§„ê³¼ ì§ì ‘ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        response_time = time.time() - start_time
        return fallback_response, "fallback", is_emergency, [], response_time
    
    def load_test_data_only(self, num_samples: int = 200) -> List[Dict]:
        """ì˜¤ì§ test ë°ì´í„°ë§Œ ë¡œë”© (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)"""
        print(f"\nğŸ“Š Test ë°ì´í„°ë§Œ ë¡œë”© ì¤‘...")
        
        # ì˜¤ì§ test íŒŒì¼ë§Œ ì‚¬ìš©
        test_files = [
            "data/processed/splits/essential_medical_test.json", 
            "data/processed/splits/professional_medical_test.json"
        ]
        
        all_data = []
        for file_path in test_files:
            if os.path.exists(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            all_data.extend(data)
                        else:
                            all_data.append(data)
                    print(f"âœ… {file_path}: {len(data) if isinstance(data, list) else 1}ê°œ ìƒ˜í”Œ")
                except Exception as e:
                    print(f"âš ï¸ {file_path} ë¡œë”© ì‹¤íŒ¨: {e}")
            else:
                print(f"âš ï¸ {file_path} íŒŒì¼ ì—†ìŒ")
        
        if not all_data:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ìƒ˜í”Œë§
        if len(all_data) > num_samples:
            all_data = random.sample(all_data, num_samples)
        
        print(f"âœ… Test ë°ì´í„°ë§Œ ë¡œë“œ ì™„ë£Œ: {len(all_data)}ê°œ ìƒ˜í”Œ")
        print(f"ğŸ”’ ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: train/validation ë°ì´í„° ì œì™¸")
        return all_data
    
    def evaluate_medical_professionalism(self, response: str) -> float:
        """ì˜ë£Œ ì „ë¬¸ì„± í‰ê°€"""
        medical_terms = [
            "ì˜ë£Œì§„", "ë³‘ì›", "ì‘ê¸‰ì‹¤", "119", "ì§„ë£Œ", "ìƒë‹´", "ì¦ìƒ", 
            "ì¹˜ë£Œ", "ì•½ë¬¼", "ë³µìš©", "ì˜ì‚¬", "ê°„í˜¸ì‚¬", "ì‘ê¸‰", "ê¸´ê¸‰"
        ]
        
        response_lower = response.lower()
        medical_count = sum(1 for term in medical_terms if term in response_lower)
        return min(medical_count / 5.0, 1.0)  # ìµœëŒ€ 1.0
    
    def evaluate_response_quality(self, response: str) -> float:
        """ì‘ë‹µ í’ˆì§ˆ í‰ê°€"""
        if not response or len(response) < 10:
            return 0.0
        
        # ê¸¸ì´ ì ìˆ˜ (20-200ì ì‚¬ì´ê°€ ì ì ˆ)
        length_score = 1.0 if 20 <= len(response) <= 200 else 0.5
        
        # ì˜ë£Œ ê´€ë ¨ì„± ì ìˆ˜
        medical_keywords = ["ì˜ë£Œ", "ë³‘ì›", "ì¦ìƒ", "ì¹˜ë£Œ", "ì•½ë¬¼", "ì˜ì‚¬"]
        medical_score = sum(1 for keyword in medical_keywords if keyword in response) / len(medical_keywords)
        
        # ë°˜ë³µì„± ì ìˆ˜ (ë°˜ë³µì´ ì ì„ìˆ˜ë¡ ì¢‹ìŒ)
        words = response.split()
        unique_words = len(set(words))
        repetition_score = unique_words / len(words) if words else 0
        
        return (length_score + medical_score + repetition_score) / 3
    
    def evaluate(self, num_samples: int = 200) -> Dict[str, Any]:
        """ì˜¬ë°”ë¥¸ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ BERTScore í‰ê°€"""
        print(f"\nğŸ” ì˜¬ë°”ë¥¸ BERTScore ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í‰ê°€ ì‹œì‘ ({num_samples}ê°œ ìƒ˜í”Œ)")
        print("=" * 60)
        print("ğŸ”’ ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: ì˜¤ì§ test ë°ì´í„°ë§Œ ì‚¬ìš©")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© (ì˜¤ì§ testë§Œ)
        test_data = self.load_test_data_only(num_samples)
        if not test_data:
            return {}
        
        # í‰ê°€ ë³€ìˆ˜
        total_samples = len(test_data)
        correct_responses = 0
        emergency_detected = 0
        symptoms_detected = 0
        total_response_time = 0
        response_sources = {"rule_based": 0, "model_based": 0, "emergency": 0, "fallback": 0}
        
        all_responses = []
        all_references = []
        
        print(f"\nğŸ¤– í•˜ì´ë¸Œë¦¬ë“œ ì‘ë‹µ ìƒì„± ì¤‘: ", end="")
        
        # ê° ìƒ˜í”Œì— ëŒ€í•´ í‰ê°€
        for i, sample in enumerate(tqdm(test_data, desc="í•˜ì´ë¸Œë¦¬ë“œ ì‘ë‹µ ìƒì„±")):
            question = sample.get("question", "")
            reference = sample.get("answer", "")
            
            if not question or not reference:
                continue
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì‘ë‹µ ìƒì„±
            response, source, is_emergency, symptoms, response_time = self.get_hybrid_response(question)
            
            # ì‘ë‹µ ìˆ˜ì§‘ (BERTScoreìš©)
            all_responses.append(response)
            all_references.append(reference)
            
            # ê¸°ë³¸ ë©”íŠ¸ë¦­ ê³„ì‚°
            total_response_time += response_time
            response_sources[source] += 1
            
            # ì‘ê¸‰ìƒí™© ê°ì§€
            if is_emergency:
                emergency_detected += 1
            
            # ì¦ìƒ ê°ì§€
            if symptoms:
                symptoms_detected += 1
            
            # ì‘ë‹µ ì •í™•ë„ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
            if any(keyword in response.lower() for keyword in ["ì˜ë£Œ", "ë³‘ì›", "ì˜ì‚¬", "ìƒë‹´", "ì¹˜ë£Œ"]):
                correct_responses += 1
        
        # BERTScore ê³„ì‚°
        print(f"\nğŸ§  BERTScore ê³„ì‚° ì¤‘...")
        try:
            P, R, F1 = score(all_responses, all_references, 
                           model_type=self.bert_model, 
                           idf=True, 
                           verbose=False)
            
            precision = P.mean().item()
            recall = R.mean().item()
            f1_score = F1.mean().item()
        except Exception as e:
            print(f"âš ï¸ BERTScore ê³„ì‚° ì˜¤ë¥˜: {e}")
            precision = recall = f1_score = 0.0
        
        # ì˜ë£Œ ì „ë¬¸ì„± ë° ì‘ë‹µ í’ˆì§ˆ í‰ê°€
        medical_scores = []
        quality_scores = []
        
        for response in all_responses:
            medical_scores.append(self.evaluate_medical_professionalism(response))
            quality_scores.append(self.evaluate_response_quality(response))
        
        avg_medical_professionalism = sum(medical_scores) / len(medical_scores) if medical_scores else 0
        avg_response_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0
        
        # ê²°ê³¼ ê³„ì‚°
        avg_response_time = total_response_time / total_samples if total_samples > 0 else 0
        response_accuracy = correct_responses / total_samples if total_samples > 0 else 0
        emergency_accuracy = emergency_detected / total_samples if total_samples > 0 else 0
        symptom_accuracy = symptoms_detected / total_samples if total_samples > 0 else 0
        overall_accuracy = (response_accuracy + emergency_accuracy + symptom_accuracy) / 3
        
        # ê²°ê³¼ ì •ë¦¬
        results = {
            "evaluation_type": "ì˜¬ë°”ë¥¸ BERTScore ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í‰ê°€ (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)",
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "data_source": "ì˜¤ì§ test ë°ì´í„°ë§Œ ì‚¬ìš©",
            "total_samples": total_samples,
            "average_response_time": avg_response_time,
            "bertscore_metrics": {
                "precision": precision,
                "recall": recall,
                "f1_score": f1_score
            },
            "medical_metrics": {
                "medical_professionalism": avg_medical_professionalism,
                "emergency_detection_accuracy": emergency_accuracy,
                "symptom_detection_accuracy": symptom_accuracy,
                "response_quality": avg_response_quality,
                "overall_accuracy": overall_accuracy
            },
            "response_sources": response_sources,
            "goals_achieved": {
                "accuracy_90_percent": overall_accuracy >= 0.9,
                "response_time_3_seconds": avg_response_time <= 3.0,
                "bertscore_f1_0_7": f1_score >= 0.7
            }
        }
        
        return results
    
    def print_results(self, results: Dict[str, Any]):
        """ê²°ê³¼ ì¶œë ¥"""
        print(f"\nğŸ¯ ì˜¬ë°”ë¥¸ BERTScore ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í‰ê°€ ê²°ê³¼")
        print("=" * 60)
        print(f"ğŸ”’ ë°ì´í„° ì†ŒìŠ¤: {results['data_source']}")
        print(f"ğŸ“Š ì´ ìƒ˜í”Œ: {results['total_samples']}ê°œ")
        print(f"â±ï¸ í‰ê·  ì‘ë‹µ ì‹œê°„: {results['average_response_time']:.2f}ì´ˆ")
        
        print(f"\nğŸ§  BERTScore ë©”íŠ¸ë¦­:")
        print(f"   Precision: {results['bertscore_metrics']['precision']:.4f}")
        print(f"   Recall: {results['bertscore_metrics']['recall']:.4f}")
        print(f"   F1-Score: {results['bertscore_metrics']['f1_score']:.4f}")
        
        print(f"\nğŸ¥ ì˜ë£Œ ì „ë¬¸ì„±: {results['medical_metrics']['medical_professionalism']:.2%}")
        print(f"ğŸš¨ ì‘ê¸‰ ê°ì§€ ì •í™•ë„: {results['medical_metrics']['emergency_detection_accuracy']:.2%}")
        print(f"ğŸ” ì¦ìƒ ê°ì§€ ì •í™•ë„: {results['medical_metrics']['symptom_detection_accuracy']:.2%}")
        print(f"â­ ì‘ë‹µ í’ˆì§ˆ: {results['medical_metrics']['response_quality']:.2%}")
        print(f"ğŸ¯ ì „ì²´ ì •í™•ë„: {results['medical_metrics']['overall_accuracy']:.2%}")
        
        print(f"\nğŸ“Š ì‘ë‹µ ì†ŒìŠ¤ ë¶„í¬:")
        for source, count in results['response_sources'].items():
            print(f"   {source}: {count}ê°œ")
        
        print(f"\nğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€:")
        goals = results['goals_achieved']
        print(f"   ì •í™•ë„ 90% ëª©í‘œ: {'âœ… ë‹¬ì„±' if goals['accuracy_90_percent'] else 'âŒ ë¯¸ë‹¬ì„±'}")
        print(f"   ì‘ë‹µ ì‹œê°„ 3ì´ˆ ëª©í‘œ: {'âœ… ë‹¬ì„±' if goals['response_time_3_seconds'] else 'âŒ ë¯¸ë‹¬ì„±'}")
        print(f"   BERTScore F1 0.7 ëª©í‘œ: {'âœ… ë‹¬ì„±' if goals['bertscore_f1_0_7'] else 'âŒ ë¯¸ë‹¬ì„±'}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì˜¬ë°”ë¥¸ BERTScore ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì˜ë£Œ ì±—ë´‡ í‰ê°€")
    print("=" * 60)
    print("ğŸ”’ ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: ì˜¤ì§ test ë°ì´í„°ë§Œ ì‚¬ìš©")
    
    # í‰ê°€ì ì´ˆê¸°í™”
    evaluator = CorrectBERTScoreHybridEvaluator()
    
    # í‰ê°€ ì˜µì…˜ ì„ íƒ
    print(f"\nğŸ“Š í‰ê°€ ì˜µì…˜:")
    print(f"   1. ë¹ ë¥¸ í‰ê°€: 100ê°œ ìƒ˜í”Œ")
    print(f"   2. í‘œì¤€ í‰ê°€: 200ê°œ ìƒ˜í”Œ")
    print(f"   3. ì „ì²´ í‰ê°€: ëª¨ë“  test ìƒ˜í”Œ")
    
    choice = input("\nì„ íƒí•˜ì„¸ìš” (1-3): ").strip()
    
    if choice == "1":
        num_samples = 100
    elif choice == "2":
        num_samples = 200
    elif choice == "3":
        num_samples = 10000  # ì¶©ë¶„íˆ í° ìˆ˜
    else:
        print("ê¸°ë³¸ê°’ 200ê°œ ìƒ˜í”Œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        num_samples = 200
    
    # í‰ê°€ ì‹¤í–‰
    results = evaluator.evaluate(num_samples)
    
    if results:
        # ê²°ê³¼ ì¶œë ¥
        evaluator.print_results(results)
        
        # ê²°ê³¼ ì €ì¥
        os.makedirs("models", exist_ok=True)
        result_file = f"models/correct_bertscore_hybrid_evaluation_results_{results['timestamp']}.json"
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {result_file}")
        print(f"\nâœ… ì˜¬ë°”ë¥¸ BERTScore ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í‰ê°€ ì™„ë£Œ!")
    else:
        print("âŒ í‰ê°€ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()
