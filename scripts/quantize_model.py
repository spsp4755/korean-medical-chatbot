#!/usr/bin/env python3
"""
ëª¨ë¸ ì–‘ìí™” ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
42dot ëª¨ë¸ì„ INT8ë¡œ ì–‘ìí™”í•˜ì—¬ í¬ê¸°ì™€ ì†ë„ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.
"""

import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.optimization.quantization import ModelQuantizer
import yaml
import json

def load_config(config_path: str = "configs/config.yaml") -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ëª¨ë¸ ì–‘ìí™” ì‹¤í—˜ ì‹œì‘")
    print("=" * 60)
    
    # ì„¤ì • ë¡œë“œ
    config = load_config()
    model_name = config["model"]["base_model_name"]
    
    print(f"ğŸ“Š ëŒ€ìƒ ëª¨ë¸: {model_name}")
    print(f"ğŸ¯ ëª©í‘œ: ëª¨ë¸ í¬ê¸° 50% ê°ì†Œ, ì¶”ë¡  ì†ë„ 2ë°° í–¥ìƒ")
    
    # ì–‘ìí™”ê¸° ì´ˆê¸°í™”
    quantizer = ModelQuantizer(
        model_name=model_name,
        output_dir="models/quantized"
    )
    
    try:
        # ì–‘ìí™” ì‹¤í—˜ ì‹¤í–‰ (ëª¨ë¸ ì••ì¶•)
        results = quantizer.run_quantization_experiment(["compression"])
        
        # ê²°ê³¼ ë¶„ì„
        print("\nğŸ“Š ì–‘ìí™” ì‹¤í—˜ ê²°ê³¼ ë¶„ì„:")
        print("=" * 60)
        
        if "original" in results:
            orig = results["original"]
            print(f"ğŸ”¹ ì›ë³¸ ëª¨ë¸:")
            print(f"  - í¬ê¸°: {orig['model_size_mb']:.2f}MB")
            print(f"  - ì¶”ë¡  ì†ë„: {orig['inference_speed_seconds']:.2f}ì´ˆ")
            print(f"  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {orig['memory_usage_mb']:.2f}MB")
        
        if "int8" in results:
            if "error" in results["int8"]:
                print(f"âŒ INT8 ì–‘ìí™” ì‹¤íŒ¨: {results['int8']['error']}")
            else:
                int8 = results["int8"]
                print(f"ğŸ”¹ INT8 ì–‘ìí™” ëª¨ë¸:")
                print(f"  - í¬ê¸°: {int8['quantized_size_mb']:.2f}MB")
                print(f"  - ì¶”ë¡  ì†ë„: {int8['quantized_speed_seconds']:.2f}ì´ˆ")
                print(f"  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {int8['quantized_memory_mb']:.2f}MB")
                print(f"  - í¬ê¸° ê°ì†Œ: {int8['size_reduction_percent']:.1f}%")
                print(f"  - ì†ë„ í–¥ìƒ: {int8['speed_improvement_percent']:.1f}%")
                
                # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
                print(f"\nğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€:")
                size_goal = int8['size_reduction_percent'] >= 50
                speed_goal = int8['speed_improvement_percent'] >= 100
                
                print(f"  - í¬ê¸° 50% ê°ì†Œ: {'âœ…' if size_goal else 'âŒ'} ({int8['size_reduction_percent']:.1f}%)")
                print(f"  - ì†ë„ 2ë°° í–¥ìƒ: {'âœ…' if speed_goal else 'âŒ'} ({int8['speed_improvement_percent']:.1f}%)")
                
                if size_goal and speed_goal:
                    print(f"\nğŸ‰ ëª¨ë“  ëª©í‘œ ë‹¬ì„±!")
                else:
                    print(f"\nâš ï¸ ì¼ë¶€ ëª©í‘œ ë¯¸ë‹¬ì„± - ì¶”ê°€ ìµœì í™” í•„ìš”")
        
        # ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
        print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"1. Pruning ê¸°ë²• ì ìš© (ê°€ì¤‘ì¹˜ 20-30% ì œê±°)")
        print(f"2. Knowledge Distillation êµ¬í˜„")
        print(f"3. LoRA íŒŒì¸íŠœë‹ ì ìš©")
        
    except Exception as e:
        print(f"âŒ ì–‘ìí™” ì‹¤í—˜ ì‹¤íŒ¨: {str(e)}")
        print(f"ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}")

if __name__ == "__main__":
    main()
